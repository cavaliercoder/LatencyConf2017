Configuring Timeouts
Latency Conference
16 Nov 2017
Tags: latency, timeouts, cloud

Ryan Armstrong
Production Engineering Manager, Seven West Media
ryan@cavaliercoder.com
http://cavaliercoder.com/
@cavaliercoder

: Seven West Media
: Production Engineering
: My role
: We are hiring

* Agenda

- Backstory
- Anatomy of a timeout
- Scenarios
- One simple rule
- Trade-offs


* Backstory

.image blog.png _ 900
# .iframe http://cavaliercoder.com/blog/webops-postmortem.html 900 600


* Backstory

Paul Hammant
DevOps and Continuous Delivery expert

.link https://paulhammant.com/ paulhammant.com

"So, a great article. You could do well to do a canonical blog entry on timeouts I think, complete with sequence diagrams. Perhaps with a simulation :)"

: Pauldescribed three similar issues
: Recommended I write about timeouts


* The goal

- Encourage systems thinking
- Sweat the details

: critial thinking about flow and interactions in a system
: I'll demonstrate some problems, solutions and tradeoffs


* Flow of requests through a system

.image system.svg

: Applies to distributed systems, micro-services and container pods

* N-Tier

.image n-tier.svg


* Monoliths?

.image monolith-1.svg


* Monoliths?

Yes!!!

.image monolith-2.svg

: hidden network components
: hidden software components (DB on same server)?
: TCP stack?


* Anatomy of a timeout

*Client*: How long do I wait for the server?

*Server*: How long will I wait for the client's request?


* Anatomy of a timeout

A HTTPS request

- Name resolution
- TCP handshake
- TLS handshake
- Transfer request headers
- Transfer request body
- Time-to-first-byte
- Transfer response headers
- Transfer response body


* Anti-pattern: Default timeouts

- Typically generous
- Optimized for local error reduction

.image default_timeouts.svg


* Benchmark

: $ fab deploy:default_timeouts
: $ fab -H centos@13.55.60.112 bench:concurrency=1

: 1 - simple load
: 2 - high load
: 3 - faulty db + singleton error

.code ../fabric/ab.sample


* Anti-pattern: Agressive timeouts

- All components optimized for local latency

.image agressive_timeouts.svg


* Benchmark

.code ../fabric/ab.sample

: 1 - gradually increase concurrency
: 2 - total failure
: 3 - response body under load
: 4 - faulty db under low load - error misplaced

: $ fab deploy:agressive_timeouts


* Anti-pattern: Equal timeouts

- All components have similar, reasonable timeouts

.image equal_timeouts.svg

: $ fab deploy:equal_timeouts

* Benchmark

.code ../fabric/ab.sample

: 1 - healthy request
: 2 - faulty db -> show error on each component



* One simple rule

    timeout(n) > T(n+1)

: T = maximum healthy time
: $ fab deploy:fixed

.image fixed.svg

* Benchmark

.code ../fabric/ab.sample

: 1 - simple load
: 2 - high load
: 3 - faulty db -> show error on each component


* Load characterisation

What is the maximum time a healthy request should take?

: Variance - E.g Static vs Dynamic | large vs small files
: Round trips - Synchronous or concurrent?
: Concurrency - Node.js event loop | Go goroutines
: Parallelism
: CPU vs. IO bound-latency - Rendering vs. Data retrieval
: Keep-alives vs. Session negotiation
: Retries and backoff
: Cache tiers and warm up
: Cancellation
: Rate limiting and throttling
: QoS
: Queues and decoupled workflows
: Upstream dependencies


* There are no simple rules

There are always tradeoffs.

* Everything must be bounded
